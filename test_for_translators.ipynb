{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Steps:\n",
        "\n",
        "\n",
        "1.   The AutoTokenizer from Hugging Face is used to tokenize the input texts (English query and Armenian passage).\n",
        "2.   The AutoModel generates the embeddings for each text and average over the token embeddings to get a single sentence-level representation using the average_pool function.\n",
        "3. Normalize the embeddings so that they are unit vectors (i.e., have a length of 1). This ensures that the cosine similarity score reflects only the direction of the embeddings and not their magnitude.\n",
        "4. The similarity score is calculated using cosine similarity between the English and Armenian embeddings. The result will give a value between 0 and 100, representing how similar the two sentences are."
      ],
      "metadata": {
        "id": "dl4Pnj6hK0Sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Load tokenizer and model for Armenian embeddings\n",
        "tokenizer = AutoTokenizer.from_pretrained('Metric-AI/armenian-text-embeddings-1')\n",
        "model = AutoModel.from_pretrained('Metric-AI/armenian-text-embeddings-1')\n",
        "\n",
        "# Function to average pool the last hidden states to get sentence-level embeddings\n",
        "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
      ],
      "metadata": {
        "id": "1dKhPtElFjT0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input sentences (English query and Armenian translation as passage)\n",
        "input_texts = [\n",
        "    'query: Can I come to your house?',  # Example query in English\n",
        "    'passage: Կարո՞ղ եմ գալ ձեր տուն։'  # Translation in Armenian\n",
        "]"
      ],
      "metadata": {
        "id": "L-oAQNJqJfkr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the input texts for the model\n",
        "batch_dict = tokenizer(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Get the model outputs for the input texts\n",
        "outputs = model(**batch_dict)\n",
        "\n",
        "# Extract sentence embeddings by averaging the last hidden states\n",
        "embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "# Normalize the embeddings (to unit vectors) before calculating similarity\n",
        "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "# Calculate cosine similarity between the English and Armenian embeddings\n",
        "# embeddings[0] = English query, embeddings[1] = Armenian passage\n",
        "similarity_score = (embeddings[0] @ embeddings[1].T) * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5cB8griMD1G",
        "outputId": "6dadef00-bd45-4789-a426-b28ed6e81b22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9be65de19c08>:15: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)\n",
            "  similarity_score = (embeddings[0] @ embeddings[1].T) * 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The program will output the cosine similarity score as a percentage.\n",
        "* A higher similarity score indicates that the translation is more faithful to the original English text."
      ],
      "metadata": {
        "id": "H42yRmR1MJ7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the similarity score (range 0-100)\n",
        "print(f\"Cosine Similarity Score: {similarity_score.item():.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3XwnFnXJ_tK",
        "outputId": "e63af5a6-3050-4643-e700-087c36b2e8bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity Score: 91.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UfW9o3gVKBrq"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}